{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpl3TZ2jl4Vh",
        "outputId": "440de4ca-0019-4bde-9d0a-e7437808783e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L47XBZWm4T9x",
        "outputId": "f0538923-27da-49dd-fbb0-d03682dd78d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V1FQTVeAuNiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3057297-153a-4611-bf79-94ed41398f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ],
      "source": [
        "# untar\n",
        "# !tar -xvzf dataset.tar.gz\n",
        "!tar -xvzf '/content/drive/MyDrive/dataset.tar.gz'\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTzcSoYl4T97",
        "outputId": "2820fa7c-0792-4517-9235-bf4670f2020a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G9Nk_MAPqZPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfe98a8-11d5-437e-b2f7-f9ba239cc9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "703/703 [==============================] - 7s 6ms/step - loss: 1.5006 - accuracy: 0.3192 - val_loss: 1.3675 - val_accuracy: 0.4194\n",
            "Epoch 2/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.3543 - accuracy: 0.4158 - val_loss: 1.2954 - val_accuracy: 0.4503\n",
            "Epoch 3/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.2920 - accuracy: 0.4501 - val_loss: 1.2251 - val_accuracy: 0.4808\n",
            "Epoch 4/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2532 - accuracy: 0.4749 - val_loss: 1.2127 - val_accuracy: 0.4891\n",
            "Epoch 5/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.2181 - accuracy: 0.4948 - val_loss: 1.1662 - val_accuracy: 0.5046\n",
            "Epoch 6/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.1819 - accuracy: 0.5147 - val_loss: 1.1416 - val_accuracy: 0.5279\n",
            "Epoch 7/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.1542 - accuracy: 0.5294 - val_loss: 1.1040 - val_accuracy: 0.5465\n",
            "Epoch 8/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.1197 - accuracy: 0.5498 - val_loss: 1.1093 - val_accuracy: 0.5398\n",
            "Epoch 9/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0944 - accuracy: 0.5600 - val_loss: 1.0431 - val_accuracy: 0.5806\n",
            "Epoch 10/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.0688 - accuracy: 0.5711 - val_loss: 1.0444 - val_accuracy: 0.5798\n",
            "Epoch 11/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0570 - accuracy: 0.5800 - val_loss: 0.9974 - val_accuracy: 0.5992\n",
            "Epoch 12/50\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.0323 - accuracy: 0.5866 - val_loss: 1.0077 - val_accuracy: 0.5980\n",
            "Epoch 13/50\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.0168 - accuracy: 0.5945 - val_loss: 0.9764 - val_accuracy: 0.6079\n",
            "Epoch 14/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.0023 - accuracy: 0.6041 - val_loss: 0.9699 - val_accuracy: 0.6075\n",
            "Epoch 15/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9846 - accuracy: 0.6102 - val_loss: 0.9650 - val_accuracy: 0.6079\n",
            "Epoch 16/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.9725 - accuracy: 0.6218 - val_loss: 0.9554 - val_accuracy: 0.6143\n",
            "Epoch 17/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.9587 - accuracy: 0.6252 - val_loss: 0.9581 - val_accuracy: 0.6123\n",
            "Epoch 18/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9458 - accuracy: 0.6274 - val_loss: 0.9234 - val_accuracy: 0.6305\n",
            "Epoch 19/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9347 - accuracy: 0.6331 - val_loss: 0.9197 - val_accuracy: 0.6376\n",
            "Epoch 20/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9194 - accuracy: 0.6425 - val_loss: 0.9094 - val_accuracy: 0.6345\n",
            "Epoch 21/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.9062 - accuracy: 0.6498 - val_loss: 0.9037 - val_accuracy: 0.6448\n",
            "Epoch 22/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8999 - accuracy: 0.6485 - val_loss: 0.8934 - val_accuracy: 0.6396\n",
            "Epoch 23/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.8830 - accuracy: 0.6567 - val_loss: 0.9211 - val_accuracy: 0.6384\n",
            "Epoch 24/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8775 - accuracy: 0.6572 - val_loss: 0.8806 - val_accuracy: 0.6491\n",
            "Epoch 25/50\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.8588 - accuracy: 0.6683 - val_loss: 0.8733 - val_accuracy: 0.6539\n",
            "Epoch 26/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.8486 - accuracy: 0.6701 - val_loss: 0.8489 - val_accuracy: 0.6634\n",
            "Epoch 27/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.8420 - accuracy: 0.6754 - val_loss: 0.8450 - val_accuracy: 0.6693\n",
            "Epoch 28/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.8272 - accuracy: 0.6814 - val_loss: 0.8450 - val_accuracy: 0.6697\n",
            "Epoch 29/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.8188 - accuracy: 0.6870 - val_loss: 0.8230 - val_accuracy: 0.6840\n",
            "Epoch 30/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8071 - accuracy: 0.6909 - val_loss: 0.8285 - val_accuracy: 0.6768\n",
            "Epoch 31/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.7961 - accuracy: 0.6964 - val_loss: 0.8192 - val_accuracy: 0.6840\n",
            "Epoch 32/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7892 - accuracy: 0.6996 - val_loss: 0.8180 - val_accuracy: 0.6788\n",
            "Epoch 33/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.7804 - accuracy: 0.7004 - val_loss: 0.8024 - val_accuracy: 0.6911\n",
            "Epoch 34/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7651 - accuracy: 0.7105 - val_loss: 0.8088 - val_accuracy: 0.6832\n",
            "Epoch 35/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7567 - accuracy: 0.7117 - val_loss: 0.7871 - val_accuracy: 0.6966\n",
            "Epoch 36/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.7516 - accuracy: 0.7127 - val_loss: 0.8029 - val_accuracy: 0.6808\n",
            "Epoch 37/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7386 - accuracy: 0.7157 - val_loss: 0.7821 - val_accuracy: 0.6923\n",
            "Epoch 38/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.7314 - accuracy: 0.7213 - val_loss: 0.7725 - val_accuracy: 0.6947\n",
            "Epoch 39/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.7247 - accuracy: 0.7242 - val_loss: 0.7891 - val_accuracy: 0.6848\n",
            "Epoch 40/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7154 - accuracy: 0.7268 - val_loss: 0.7648 - val_accuracy: 0.7030\n",
            "Epoch 41/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.7062 - accuracy: 0.7339 - val_loss: 0.8192 - val_accuracy: 0.6808\n",
            "Epoch 42/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6963 - accuracy: 0.7325 - val_loss: 0.7584 - val_accuracy: 0.7053\n",
            "Epoch 43/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.6950 - accuracy: 0.7355 - val_loss: 0.7664 - val_accuracy: 0.6950\n",
            "Epoch 44/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6818 - accuracy: 0.7382 - val_loss: 0.7698 - val_accuracy: 0.6974\n",
            "Epoch 45/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6815 - accuracy: 0.7418 - val_loss: 0.7648 - val_accuracy: 0.7022\n",
            "Epoch 46/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6732 - accuracy: 0.7437 - val_loss: 0.7465 - val_accuracy: 0.7089\n",
            "Epoch 47/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.6618 - accuracy: 0.7478 - val_loss: 0.7552 - val_accuracy: 0.7030\n",
            "Epoch 48/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.6594 - accuracy: 0.7495 - val_loss: 0.7281 - val_accuracy: 0.7172\n",
            "Epoch 49/50\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6471 - accuracy: 0.7535 - val_loss: 0.7511 - val_accuracy: 0.7057\n",
            "Epoch 50/50\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.6496 - accuracy: 0.7543 - val_loss: 0.7587 - val_accuracy: 0.7137\n"
          ]
        }
      ],
      "source": [
        "# you can use the default hyper-parameters for training, \n",
        "# and val accuracy ~59% after 25 epochs and > 63% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=50, \n",
        "                   validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOhpP7M24T9_",
        "outputId": "bfe369f7-fa0b-477c-c0e3-e1923ed37536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7587 - accuracy: 0.7137\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MuTDYyc6p1it"
      },
      "outputs": [],
      "source": [
        "def sparsity(weights):\n",
        "  zero_weights = 0\n",
        "  total_weights = 0\n",
        "  for i in range(len(weights)):\n",
        "    curr_zero_weights = tf.reduce_sum((weights[i]==0)*1).numpy()\n",
        "    # print(curr_zero_weights)\n",
        "    zero_weights += curr_zero_weights\n",
        "    total_weights += weights[i].reshape(-1).shape[0]\n",
        "  return zero_weights / total_weights\n",
        "\n",
        "def score(acc, sparsity):\n",
        "  return (acc + sparsity)/2\n",
        "\n",
        "def magnitude_based_pruning(weights, threshold):\n",
        "  for i in range(len(weights)):\n",
        "    weights[i] = (abs(weights[i]) > threshold)  * weights[i]\n",
        "  return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MPiJ_b1S4T-I"
      },
      "outputs": [],
      "source": [
        "def l1_norm_pruning(weights, m=10):\n",
        "  for i in range(8):\n",
        "    if i%2 == 0:\n",
        "      sum_weights = tf.reduce_sum(abs(weights[i]), axis=[0,1,2])\n",
        "      sort_idx = np.argsort(sum_weights)\n",
        "      prune_filters = sort_idx[:m]\n",
        "      weights[i][:,:,:,prune_filters] = 0\n",
        "      weights[i+1][prune_filters] = 0\n",
        "\n",
        "  return weights  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = 3\n",
        "loop = 5\n",
        "epoch_per_train = 5\n",
        "for i in range(loop):\n",
        "  print()\n",
        "  print('i: {}/{}'.format(i,loop))\n",
        "  history = model.fit(train_images, train_labels, batch_size=32, epochs=epoch_per_train, \n",
        "                    validation_data=(val_images, val_labels), verbose=False)\n",
        "  weights = model.get_weights()\n",
        "  new_weights = l1_norm_pruning(weights, m=m)\n",
        "  model.set_weights(new_weights)\n",
        "\n",
        "  results = model.evaluate(val_images, val_labels, batch_size=128, verbose=False)\n",
        "  sparsity_model = sparsity(model.get_weights())\n",
        "  score_model  = score(results[1], sparsity_model)\n",
        "  print('Accuracy: {:.3f} || Sparsity: {:.5f} || Score: {:.3f}'.format(results[1],sparsity_model,score_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lcTVM6UI4A6",
        "outputId": "280f5e53-0224-42eb-d95f-98511d0913fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "i: 0/5\n",
            "Accuracy: 0.672 || Sparsity: 0.00599 || Score: 0.339\n",
            "\n",
            "i: 1/5\n",
            "Accuracy: 0.721 || Sparsity: 0.00599 || Score: 0.364\n",
            "\n",
            "i: 2/5\n",
            "Accuracy: 0.731 || Sparsity: 0.00599 || Score: 0.369\n",
            "\n",
            "i: 3/5\n",
            "Accuracy: 0.732 || Sparsity: 0.00599 || Score: 0.369\n",
            "\n",
            "i: 4/5\n",
            "Accuracy: 0.743 || Sparsity: 0.00599 || Score: 0.374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0EPNCf9jDzy",
        "outputId": "ffd7f7dd-38bf-4b44-f550-4c45ce94eecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.7426\n",
            "Sparsity of the model: 0.005985499205\n",
            "Score of the model: 0.374280\n"
          ]
        }
      ],
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model.evaluate(val_images, val_labels, batch_size=128)\n",
        "sparsity_model = sparsity(model.get_weights())\n",
        "score_model  = score(results[1], sparsity_model)\n",
        "\n",
        "print('Sparsity of the model: {:.12f}'.format(sparsity_model))\n",
        "print('Score of the model: {:6f}'.format(score_model))\n",
        "# assert np.less(0.60, results[1]), 'Not getting desired accuracy'\n",
        "# assert np.less(0.36, score_model), 'Not getting desired score'\n",
        "# assert np.less(0, sparsity_model), 'No sparsity in the model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6JsQ5K1-e-KU",
        "outputId": "cd0827de-4791-4f12-f43a-057c51ffe4c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a9d84f79-920e-4008-a4b4-539b942af8cb\", \"my_model_weights_2.h5\", 2407560)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model_name = \"my_model_weights_2.h5\"\n",
        "model.save_weights(model_name)\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MPvmre8lfbe-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}